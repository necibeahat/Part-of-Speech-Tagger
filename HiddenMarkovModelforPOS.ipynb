{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Jupyter \"magic methods\" run once per kernel restart\n",
    "%load_ext autoreload\n",
    "%aimport helpers, tests\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python libraries \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from itertools import chain, combinations\n",
    "from collections import Counter, defaultdict\n",
    "from helpers import show_model, Dataset\n",
    "\n",
    "# This script uses Hidden Markov Model from pomegranate python library\n",
    "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Data sets is from the Brown corpus and the unversal tagset originally from NLTK. The code below will split the data into two sets. %80 of the data will be used as a training set, while the remaining data is the test set. There are approximately 57k sentences in the corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: b100-50001\n",
      "words:\n",
      "\t('Mmmm', ',', 'it', 'sure', 'itches', \"''\", '.')\n",
      "tags:\n",
      "\t('PRT', '.', 'PRON', 'ADV', 'VERB', '.', '.')\n",
      "There are a total of 1161192 samples of 56057 unique words in the corpus.\n",
      "There are 5521 words in the test set that are missing in the training set.\n",
      "Sentence 1: ('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.')\n",
      "\n",
      "Labels 1: ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "Sentence 2: ('But', 'there', 'seemed', 'to', 'be', 'some', 'difference', 'of', 'opinion', 'as', 'to', 'how', 'far', 'the', 'board', 'should', 'go', ',', 'and', 'whose', 'advice', 'it', 'should', 'follow', '.')\n",
      "\n",
      "Labels 2: ('CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADP', 'ADV', 'ADV', 'DET', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', '.')\n",
      "\n",
      "\n",
      "Stream (word, tag) pairs:\n",
      "\n",
      "\t ('Mr.', 'NOUN')\n",
      "\t ('Podger', 'NOUN')\n",
      "\t ('had', 'VERB')\n",
      "\t ('thanked', 'VERB')\n",
      "\t ('him', 'PRON')\n",
      "\t ('gravely', 'ADV')\n",
      "\t (',', '.')\n",
      "Total number of sentences in the corpus: 57340\n"
     ]
    }
   ],
   "source": [
    "# Split the data into test and training set\n",
    "data = Dataset(\"tags-universal.txt\", \"brown-universal.txt\", train_test_split=0.8)\n",
    "\n",
    "# How to access the data\n",
    "assert len(data) == len(data.training_set) + len(data.testing_set), \\\n",
    "       \"The number of sentences in the training set + testing set should sum to the number of sentences in the corpus\"\n",
    "\n",
    "# access given sentence       \n",
    "key = 'b100-50001'\n",
    "print(\"Sentence: {}\".format(key))\n",
    "print(\"words:\\n\\t{!s}\".format(data.sentences[key].words))\n",
    "print(\"tags:\\n\\t{!s}\".format(data.sentences[key].tags))\n",
    "\n",
    "# access unique words\n",
    "# count unique words\n",
    "print(\"There are a total of {} samples of {} unique words in the corpus.\"\n",
    "      .format(data.N, len(data.vocab)))\n",
    "print(\"There are {} words in the test set that are missing in the training set.\"\n",
    "      .format(len(data.testing_set.vocab - data.training_set.vocab)))\n",
    "\n",
    "assert data.N == data.training_set.N + data.testing_set.N, \\\n",
    "       \"The number of training + test samples should sum to the total number of samples\"\n",
    "       \n",
    "# access words and tags\n",
    "for i in range(2):    \n",
    "    print(\"Sentence {}:\".format(i + 1), data.X[i])\n",
    "    print()\n",
    "    print(\"Labels {}:\".format(i + 1), data.Y[i])\n",
    "    print()\n",
    "    \n",
    "# access word and tag\n",
    "# use Dataset.stream() (word, tag) samples for the entire corpus\n",
    "print(\"\\nStream (word, tag) pairs:\\n\")\n",
    "for i, pair in enumerate(data.stream()):\n",
    "    print(\"\\t\", pair)\n",
    "    if i > 5: break\n",
    "    \n",
    "    \n",
    "print(\"Total number of sentences in the corpus: {}\".format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Tagger - Most Frequent Class\n",
    "\n",
    "One of the simplest way to assign a tag to a word is to check how often certain word (e.g. Jane) is tagged with what lexical category, and assign the most frequent tag to the word. for example is the word *Jane* is mostly tagged as a noun, the 'Most Frequent Class' tagger will tag Jane as a noun. \n",
    "This is a simple but effective method. However, if the same word appears in text in more than one lexical category, the tagger perform poorly. For example, take these two sentences: \n",
    " 1- **It’s an interesting book. (noun)*\n",
    " 2- **We ought to book a holiday soon. (verb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Emission counts are calculated!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pair_counts(sequences_A, sequences_B):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the first sequence list\n",
    "    that counts the number of occurrences of the corresponding value from the\n",
    "    second sequences list.\n",
    "    \"\"\"\n",
    "    \n",
    "    #initiate the counter\n",
    "    most_freq_PoS = defaultdict(Counter)\n",
    "\n",
    "    for i in range(len(sequences_A)):\n",
    "        #combine words with tags per sentence & order, count how many times each tag occurs\n",
    "        for tag, word in zip(sequences_A[i], sequences_B[i]):\n",
    "            most_freq_PoS[tag][word] +=1\n",
    "    \n",
    "    return most_freq_PoS\n",
    "    raise NotImplementedError\n",
    "\n",
    "# Calculate C(t_i, w_i)\n",
    "emission_counts = pair_counts(data.training_set.Y, data.training_set.X) #returns dict per PoS and corrosponding word + count\n",
    "\n",
    "assert len(emission_counts) == 12, \\\n",
    "       \"Uh oh. There should be 12 tags in your dictionary.\"\n",
    "assert max(emission_counts[\"NOUN\"], key=emission_counts[\"NOUN\"].get) == 'time', \\\n",
    "       \"Hmmm...'time' is expected to be the most common NOUN.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Emission counts are calculated!</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Lookup table with words and corresponsing coulds</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a lookup table simple_table where simple_table[word] contains the tag label most frequently assigned to that word\n",
    "from collections import namedtuple\n",
    "\n",
    "FakeState = namedtuple(\"FakeState\", \"name\")\n",
    "\n",
    "class SimpleTagger:\n",
    "    # NOTE: You should not need to modify this class or any of its methods\n",
    "    missing = FakeState(name=\"<MISSING>\")\n",
    "    \n",
    "    def __init__(self, table):\n",
    "        self.table = defaultdict(lambda: SimpleTagger.missing)\n",
    "        self.table.update({word: FakeState(name=tag) for word, tag in table.items()})\n",
    "        \n",
    "    def viterbi(self, seq):\n",
    "        \"\"\"This method simplifies predictions by matching the Pomegranate viterbi() interface\"\"\"\n",
    "        return 0., list(enumerate([\"<start>\"] + [self.table[w] for w in seq] + [\"<end>\"]))\n",
    "\n",
    "\n",
    "# calculate the frequency of each tag being assigned to each word and fill the simple_tagger_table\n",
    "\n",
    "# returns PoS counts for each word\n",
    "word_counts = pair_counts(data.training_set.X, data.training_set.Y)\n",
    "\n",
    "#initiate the table\n",
    "simple_tagger_table = defaultdict()\n",
    "\n",
    "for word, tag_group in word_counts.items():\n",
    "    #for each word, record only the highest occuring PoS\n",
    "    most_common_word = [word for word, count in Counter(tag_group).most_common(1)]\n",
    "    simple_tagger_table[word] = ''.join(most_common_word)\n",
    "\n",
    "# Create a Most Frequent Class tagger instance\n",
    "simple_tagger_model = SimpleTagger(simple_tagger_table) \n",
    "\n",
    "assert len(simple_tagger_table) == len(data.training_set.vocab), \"\"\n",
    "assert all(k in data.training_set.vocab for k in simple_tagger_table.keys()), \"\"\n",
    "assert sum(int(k not in simple_tagger_table) for k in data.testing_set.vocab) == 5521, \"\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Lookup table with words and corresponsing coulds</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with the most frequent class tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-28144\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-23146\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def replace_unknown(sequence):\n",
    "    \"\"\"Return a copy of the input sequence where each unknown word is replaced\n",
    "    by the literal string value 'nan'. Pomegranate will ignore these values\n",
    "    during computation.\n",
    "    \"\"\"\n",
    "    return [w if w in data.training_set.vocab else 'nan' for w in sequence]\n",
    "\n",
    "def simplify_decoding(X, model):\n",
    "    \"\"\"X should be a 1-D sequence of observations for the model to predict\"\"\"\n",
    "    _, state_path = model.viterbi(replace_unknown(X))\n",
    "    return [state[1].name for state in state_path[1:-1]]  # do not show the start/end state predictions\n",
    "\n",
    "for key in data.testing_set.keys[:2]:\n",
    "    print(\"Sentence Key: {}\\n\".format(key))\n",
    "    print(\"Predicted labels:\\n-----------------\")\n",
    "    print(simplify_decoding(data.sentences[key].words, simple_tagger_model))\n",
    "    print()\n",
    "    print(\"Actual labels:\\n--------------\")\n",
    "    print(data.sentences[key].tags)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Evaluate the accuracy of the model on the full corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy simple_model: 95.72%\n",
      "testing accuracy simple_tagger: 93.01%\n"
     ]
    }
   ],
   "source": [
    "def accuracy(X, Y, model):\n",
    "    \"\"\"Calculate the prediction accuracy by using the model to decode each sequence\n",
    "    in the input X and comparing the prediction with the true labels in Y.\n",
    "    \n",
    "    The X should be an array whose first dimension is the number of sentences to test,\n",
    "    and each element of the array should be an iterable of the words in the sequence.\n",
    "    The arrays X and Y should have the exact same shape.\n",
    "    \n",
    "    X = [(\"See\", \"Spot\", \"run\"), (\"Run\", \"Spot\", \"run\", \"fast\"), ...]\n",
    "    Y = [(), (), ...]\n",
    "    \"\"\"\n",
    "    correct = total_predictions = 0\n",
    "    for observations, actual_tags in zip(X, Y):\n",
    "        \n",
    "        # The model.viterbi call in simplify_decoding will return None if the HMM\n",
    "        # raises an error (for example, if a test sentence contains a word that\n",
    "        # is out of vocabulary for the training set). Any exception counts the\n",
    "        # full sentence as an error (which makes this a conservative estimate).\n",
    "        try:\n",
    "            most_likely_tags = simplify_decoding(observations, model)\n",
    "            correct += sum(p == t for p, t in zip(most_likely_tags, actual_tags))\n",
    "        except:\n",
    "            pass\n",
    "        total_predictions += len(observations)\n",
    "    return correct / total_predictions\n",
    "\n",
    "simple_tagger_training_acc = accuracy(data.training_set.X, data.training_set.Y, simple_tagger_model)\n",
    "print(\"training accuracy simple_model: {:.2f}%\".format(100 * simple_tagger_training_acc))\n",
    "\n",
    "simple_tagger_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, simple_tagger_model)\n",
    "print(\"testing accuracy simple_tagger: {:.2f}%\".format(100 * simple_tagger_testing_acc))\n",
    "\n",
    "assert simple_tagger_training_acc >= 0.955, \"Most frequent count tagger accuracy on the training set doesn't look right.\"\n",
    "assert simple_tagger_testing_acc >= 0.925, \"Most frequent count tagger accuracy on the testing set doesn't look right.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model Tagger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Unigrams correct!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unigram_counts(sequences):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the input sequence list that\n",
    "    counts the number of occurrences of the value in the sequences list. The sequences\n",
    "    collection should be a 2-dimensional array.\n",
    "    \n",
    "    For example, if the tag NOUN appears 275558 times over all the input sequences,\n",
    "    then you should return a dictionary such that your_unigram_counts[NOUN] == 275558.\n",
    "    \"\"\"\n",
    "    #initiate a table\n",
    "    unigram_table = defaultdict(int)\n",
    "    \n",
    "    #iterate over each sentence of tags\n",
    "    for sentence in sequences:\n",
    "        #count # of occurances of each tag in a sentence\n",
    "        for tag in sentence:\n",
    "            unigram_table[tag] +=1\n",
    "            \n",
    "    return unigram_table\n",
    "    raise NotImplementedError\n",
    "\n",
    "# Call unigram counts on training set\n",
    "tag_unigrams = unigram_counts(data.training_set.Y)\n",
    "\n",
    "# Check if tags are assigned correctly\n",
    "assert set(tag_unigrams.keys()) == data.training_set.tagset, \\\n",
    "       \"Tag counts doesn't include all the tags!\"\n",
    "assert min(tag_unigrams, key=tag_unigrams.get) == 'X', \\\n",
    "       \"Classes arent assigned accurately. 'X' is expected to be the least common class\"\n",
    "assert max(tag_unigrams, key=tag_unigrams.get) == 'NOUN', \\\n",
    "       \"Classes arent assigned accurately.'NOUN' is expected to be the most common class\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Unigrams correct!</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Bigrams are correct!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bigram_counts(sequences):\n",
    "    \"\"\"Return a dictionary keyed to each unique PAIR of values in the input sequences\n",
    "    list that counts the number of occurrences of pair in the sequences list. The input\n",
    "    should be a 2-dimensional array.\n",
    "    \n",
    "    For example, if the pair of tags (NOUN, VERB) appear 61582 times, then you should\n",
    "    return a dictionary such that your_bigram_counts[(NOUN, VERB)] == 61582\n",
    "    \"\"\"\n",
    "    pair = []\n",
    "\n",
    "    # iterate over tags for all sentences\n",
    "    for i in range(len(sequences)):\n",
    "        sentence = sequences[i]\n",
    "        #iterate over each sentence\n",
    "        for j in range(len(sentence)-1):\n",
    "            #create a pair combination for tags in each sentece\n",
    "            pair.append((sentence[j],sentence[j+1]))\n",
    "\n",
    "    return Counter(pair)\n",
    "    raise NotImplementedError\n",
    "\n",
    "# Call bigram counts on training set\n",
    "tag_bigrams = bigram_counts(data.training_set.Y)\n",
    "\n",
    "# Check if tags are assigned correctly\n",
    "assert len(tag_bigrams) == 144, \\\n",
    "       \"Uh oh. There should be 144 pairs of bigrams (12 tags x 12 tags)\"\n",
    "assert min(tag_bigrams, key=tag_bigrams.get) in [('X', 'NUM'), ('PRON', 'X')], \\\n",
    "       \"Classes arent assigned accurately. The least common bigram should be one of ('X', 'NUM') or ('PRON', 'X').\"\n",
    "assert max(tag_bigrams, key=tag_bigrams.get) in [('DET', 'NOUN')], \\\n",
    "       \"Classes arent assigned accurately. ('DET', 'NOUN') is expected to be the most common bigram.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Bigrams are correct!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the bigram probability of sequence starting with each tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Ending tag counts are accurate!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def starting_counts(sequences):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the input sequences list\n",
    "    that counts the number of occurrences where that value is at the beginning of\n",
    "    a sequence.\n",
    "    \n",
    "    For example, if 8093 sequences start with NOUN, then you should return a\n",
    "    dictionary such that your_starting_counts[NOUN] == 8093\n",
    "    \"\"\"\n",
    "    # TODO: Finish this function!\n",
    "    first_tag = []\n",
    "\n",
    "    for sentence in sequences:\n",
    "        first_tag.append(sentence[0])\n",
    "        \n",
    "    return(Counter(first_tag))\n",
    "\n",
    "    raise NotImplementedError\n",
    "\n",
    "def ending_counts(sequences):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the input sequences list\n",
    "    that counts the number of occurrences where that value is at the end of\n",
    "    a sequence.\n",
    "    \n",
    "    For example, if 18 sequences end with DET, then you should return a\n",
    "    dictionary such that your_starting_counts[DET] == 18\n",
    "    \"\"\"\n",
    "    # TODO: Finish this function!\n",
    "    last_tag = []\n",
    "\n",
    "    for sentence in sequences:\n",
    "        last_tag.append(sentence[len(sentence)-1])\n",
    "        \n",
    "    return(Counter(last_tag))\n",
    "    raise NotImplementedError\n",
    "\n",
    "# Calculate the count of each tag starting a sequence\n",
    "tag_starts = starting_counts(data.training_set.Y)\n",
    "# Check if tags are assigned correctly\n",
    "assert len(tag_starts) == 12, \"Uh oh. There should be 12 tags in your dictionary.\"\n",
    "assert min(tag_starts, key=tag_starts.get) == 'X', \"Classes arent assigned accurately.'X' is expected to be the least common starting bigram.\"\n",
    "assert max(tag_starts, key=tag_starts.get) == 'DET', \"Classes arent assigned accurately.'DET' is expected to be the most common starting bigram.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Starting tag counts are accurate!</div>')\n",
    "\n",
    "# Calculate the count of each tag ending a sequence\n",
    "tag_ends = ending_counts(data.training_set.Y)\n",
    "\n",
    "assert len(tag_ends) == 12, \"Uh oh. There should be 12 tags in your dictionary.\"\n",
    "assert min(tag_ends, key=tag_ends.get) in ['X', 'CONJ'], \"Classes arent assigned accurately.'X' or 'CONJ' should be the least common ending bigram.\"\n",
    "assert max(tag_ends, key=tag_ends.get) == '.', \"Classes arent assigned accurately.'.' is expected to be the most common ending bigram.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Ending tag counts are accurate!</div>')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">HMM network topology is good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_model = HiddenMarkovModel(name=\"base-hmm-tagger\")\n",
    "\n",
    "unique_tags = data.training_set.tagset # get unique tags\n",
    "tag_unigrams = unigram_counts(data.training_set.Y) # get tag counts\n",
    "emission_counts = pair_counts(data.training_set.Y, data.training_set.X) # get possible words per tag\n",
    "tag_bigrams = bigram_counts(data.training_set.Y) # count of two PoS together\n",
    "states = dict()\n",
    "\n",
    "# calculate emission probabilities\n",
    "for tag in unique_tags:\n",
    "\n",
    "    emission_prob_table = dict()\n",
    "    # emission prob for each word per tag\n",
    "    for observation, count in emission_counts[tag].items():\n",
    "            emission_prob_table[observation] = count / tag_unigrams[tag]\n",
    "       \n",
    "    # emission probability distributions\n",
    "    word_tag_emissions = DiscreteDistribution(emission_prob_table)\n",
    "    word_tag_state = State(word_tag_emissions, name=tag)\n",
    "    states[tag] = word_tag_state\n",
    "       \n",
    "    # add one stage per tag\n",
    "    basic_model.add_states(word_tag_state)       \n",
    "\n",
    "# add edges between states for the observed transition frequencies P(tag_i | tag_i-1)\n",
    "\n",
    "# calculate start and end state probabilities\n",
    "start_probs_table = dict()\n",
    "for tag in unique_tags:\n",
    "    # calculate the probabilities for starting state\n",
    "    start_probs_table = tag_starts[tag]/ len(tag_starts)\n",
    "       \n",
    "    # add all possible states from the start\n",
    "    basic_model.add_transition(basic_model.start, states[tag] ,start_probs_table)\n",
    "       \n",
    "    # calculate probability for end state\n",
    "    end_probs_table = tag_ends[tag] / tag_unigrams[tag]\n",
    "    basic_model.add_transition(states[tag], basic_model.end, end_probs_table)\n",
    "\n",
    "# calculate transitional probabilities\n",
    "transition_probs_table = dict()\n",
    "for tag1, tag2 in tag_bigrams:\n",
    "    transition_probs_table =  tag_bigrams[tag1, tag2] / tag_unigrams[tag1]\n",
    "    basic_model.add_transition(states[tag1], states[tag2], transition_probs_table)\n",
    "      \n",
    "# finalize the model\n",
    "basic_model.bake()\n",
    "\n",
    "assert all(tag in set(s.name for s in basic_model.states) for tag in data.training_set.tagset), \\\n",
    "       \"Every state in your network should use the name of the associated tag, which must be one of the training set tags.\"\n",
    "assert basic_model.edge_count() == 168, \\\n",
    "       (\"Your network should have an edge from the start node to each state, one edge between every \" +\n",
    "        \"pair of tags (states), and an edge from each state to the end node.\")\n",
    "HTML('<div class=\"alert alert-block alert-success\">HMM network topology is good!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the accuracy of the HMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy basic hmm model: 97.54%\n",
      "testing accuracy basic hmm model: 95.95%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">HMM tagger accuracy looks correct!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_training_acc = accuracy(data.training_set.X, data.training_set.Y, basic_model)\n",
    "print(\"training accuracy basic hmm model: {:.2f}%\".format(100 * hmm_training_acc))\n",
    "\n",
    "hmm_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, basic_model)\n",
    "print(\"testing accuracy basic hmm model: {:.2f}%\".format(100 * hmm_testing_acc))\n",
    "\n",
    "assert hmm_training_acc > 0.97, \"HMM accuracy on the training set is not correct.\"\n",
    "assert hmm_testing_acc > 0.955, \"HMM accuracy on the testing set is not correct.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">HMM tagger accuracy looks correct!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the assign tag vs the actual tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-28144\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-23146\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data.testing_set.keys[:2]:\n",
    "    print(\"Sentence Key: {}\\n\".format(key))\n",
    "    print(\"Predicted labels:\\n-----------------\")\n",
    "    print(simplify_decoding(data.sentences[key].words, basic_model))\n",
    "    print()\n",
    "    print(\"Actual labels:\\n--------------\")\n",
    "    print(data.sentences[key].tags)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
